{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_cleaning_solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9Y85ZHVMYSL9ECj4tlSsE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oliverrmaa/data-wrangling-springboard/blob/main/solutions/data_cleaning_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kpq0RIi3X3by"
      },
      "source": [
        "# Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RZIdvdaX4-s"
      },
      "source": [
        "# Imports:\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Google Drive mount authentication\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtKLyts2vBbC"
      },
      "source": [
        "# Clone instructor's git repo over to access data \n",
        "!git clone https://github.com/oliverrmaa/data-wrangling-springboard.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZdZUD_xHcnH"
      },
      "source": [
        "# 1. Fetch Data & Basic Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XWRj7jMi3G9"
      },
      "source": [
        "Here we will grab data from an Excel File located in our github repo. We will \n",
        "use Pandas to extract from the file and also do some brief basic summary level\n",
        "explorations of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsgXvh1JuLER"
      },
      "source": [
        "PATH = \"/content/data-wrangling-springboard/data/movie_ratings.xlsx\"\n",
        "excel_file = pd.ExcelFile(PATH)\n",
        "\n",
        "df_list = [excel_file.parse(sheet_name) for sheet_name in excel_file.sheet_names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FZdy3acuq2r"
      },
      "source": [
        "df_movies = df_list[0]\n",
        "df_rating = df_list[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctwRkIbejHNr"
      },
      "source": [
        "## 1.1 Ratings Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWnpYAuvjOu1"
      },
      "source": [
        "Lets first explore the ratings dataset. We can also assess whether the ratings \n",
        "are discrete are continuous. That would be important information to know from\n",
        "a modeling perspective as a Data Scientist."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1_wffcuu97A"
      },
      "source": [
        "df_rating.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CX1sohBPJYxV"
      },
      "source": [
        "df_rating.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlwbqEGdCugH"
      },
      "source": [
        "df_rating.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMG09Jd4kO6W"
      },
      "source": [
        "df_rating[\"rating\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYmJQsjbkPNH"
      },
      "source": [
        "sns.histplot(data=df_rating, x=\"rating\", kde=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn8D1DehkUci"
      },
      "source": [
        "# 1.2 Movies Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvswPPS3JSJ2"
      },
      "source": [
        "df_movies.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwyT9wLPJWzZ"
      },
      "source": [
        "df_movies.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DHG9oUnC4LO"
      },
      "source": [
        "df_movies.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q2f8T_gW8U2"
      },
      "source": [
        "# 2. Removing Duplicates"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsKTPTZeeAS8"
      },
      "source": [
        "First, we want to be aware which columns (or combination of column)\n",
        "uniquely identify a row. This is also called a surrogate key in database terms. It will make our cleaning much easier if we can identify these things, especially when it comes to duplicates. Afterwards, we can remove these duplicates."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxX4wcVaJ-Ie"
      },
      "source": [
        "df_rating[df_rating.duplicated(['userId', 'timestamp'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFBiRQeKFSDs"
      },
      "source": [
        "df_rating[(df_rating.userId == 1) & (df_rating.timestamp == 964981179)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2BAfJDrDRR3"
      },
      "source": [
        "df_rating[df_rating.duplicated(['userId', 'timestamp', 'movieId'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AH_9zrb0oPy"
      },
      "source": [
        "It seems there are no duplicates in the ratings dataset, data is unique\n",
        "for each `timestamp`, `userId`, and `movieId`, or in other words, each row\n",
        "is a unique rating of a movie at a timestamp from a certain user. \n",
        "\n",
        "Lets now explore the movies dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkJpbBdu0hue"
      },
      "source": [
        "df_movies[df_movies.duplicated(['movieId'])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHs2o0vN0smy"
      },
      "source": [
        "df_movies[df_movies.movieId == 261]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4aEf61B1kSR"
      },
      "source": [
        "df_movies = df_movies[df_movies.movieId != 261]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iija9xyx1pqE"
      },
      "source": [
        "df_movies[df_movies.movieId == 261]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR2PlsOz07qu"
      },
      "source": [
        " For the movies dataset, there was one duplicate entry. \"Star Wars\" and \"Little Women\" are definitely not the same movie. We therefore have to drop all \n",
        "movieIds with 261 because we cannot recover whether the rating will be for\n",
        "\"Star Wars\" or \"Little Women\" after joining the two datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfooDCTk1RAk"
      },
      "source": [
        "# 3. Remove Nulls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy6dydO33eEi"
      },
      "source": [
        "Now we can assess each column in each dataset for nulls. Let's write a function\n",
        "this time to iterate through the columns to see how much nulls there are."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83gTsE0C1J0i"
      },
      "source": [
        "for column in df_rating.columns:\n",
        "  null_count = len(df_rating[df_rating[column].isna()])\n",
        "  print(\"{} : {}\".format(column, null_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZhdikzT1VAB"
      },
      "source": [
        "for column in df_movies.columns:\n",
        "  null_count = len(df_movies[df_movies[column].isna()])\n",
        "  print(\"{} : {}\".format(column, null_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrWd4PoQ3wZl"
      },
      "source": [
        "df_rating = df_rating.dropna(how='any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7ZrqYCv4cZL"
      },
      "source": [
        "df_rating[df_rating[\"rating\"].isna()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hskJy8Qc4mfo"
      },
      "source": [
        "# 4. Join Tables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8WhYycS4hv4"
      },
      "source": [
        "df = df_rating.merge(df_movies, on='movieId', how='left')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8INcbsNf6AFk"
      },
      "source": [
        "# Could not recover the movieID for two movies due to duplicate issue\n",
        "# Some rows will be null, lets just drop those\n",
        "df = df.dropna(how='any')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FciY6irG6D2o"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_igYdnCI60uN"
      },
      "source": [
        "# 5. Exercises!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrjVoluq63hw"
      },
      "source": [
        "We have one wrangled, cleaned, and consolidated dataset now. But there is more potential work to be done!\n",
        "1. The `title` column actually has the year of the movie which could be a useful\n",
        "   feature. Can we extract this? \n",
        "2. The `genres` are one giant string, can we make this more useful of a column?\n",
        "   Perhaps change it to a list. \n",
        "3. We saw earlier there were outliers in `ratings`. Can we clean this up a bit?\n",
        "4. The `timestamp` column is in unix time which is not very user friendly. Can \n",
        "   we convert it to something more meaningful?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlssAl8i79av"
      },
      "source": [
        "## 5.1 Excercise: Extract year from title column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9HrPeok8QqL"
      },
      "source": [
        "# YOUR CODE GOES HERE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT8QORqJ3ODd"
      },
      "source": [
        "df[\"year\"] = df['title'].str.split().str[-1].str.replace(\"(\", \"\").str.replace(\")\", \"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZw6sTrx3OyM"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI1i5AiM8Crs"
      },
      "source": [
        "## 5.2 Excercise: Convert Genres to a List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzkOB8GYqUWi"
      },
      "source": [
        "Bonus Exercise: How would you filter rows based on this column of lists?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "859Mxksu8R0y"
      },
      "source": [
        "# YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZN0685Y3SWL"
      },
      "source": [
        "df['genres'] = df['genres'].str.split(\"|\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df0RzyfC3Wns"
      },
      "source": [
        "# Bonus Exercise:\n",
        "df[df['genres'].apply(lambda x: 'Action' in x)].head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4GzyStl8G_q"
      },
      "source": [
        "## 5.3 Excercise: Convert Unix Timestamp to Human-Readable Timestamp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CU_Tn8G3uQP"
      },
      "source": [
        "Hint: Use the pandas method pd.to_datetime()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AChgJ0Qk8Snq"
      },
      "source": [
        "# YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um7wb1Mj3cj9"
      },
      "source": [
        "# This was a trick question, some of the timestamps are actually incorrectly formatted\n",
        "df[\"timestamp\"].astype(\"str\").str.len().unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLAVZ4KA3gdW"
      },
      "source": [
        "# The 11 digit timestamps are somewhere 200 years from now\n",
        "df[df[\"timestamp\"].astype(\"str\").str.len() == 11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RlduJ833jQR"
      },
      "source": [
        "# Removing them, we still see we have some timestamp drift\n",
        "df_correct_timestamps = df[df[\"timestamp\"].astype(\"str\").str.len() != 11]\n",
        "pd.to_datetime(df_correct_timestamps['timestamp'], unit='s').max()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DgG6I2g3luW"
      },
      "source": [
        "# Remove wrong digit length first\n",
        "df = df[df[\"timestamp\"].astype(\"str\").str.len() != 11]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PFHLBQ33oMW"
      },
      "source": [
        "# Convert to UTC\n",
        "df[\"timestamp\"] = pd.to_datetime(df['timestamp'], unit='s', utc=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwoC_hWP3qV2"
      },
      "source": [
        "import datetime\n",
        "now = datetime.datetime.now()\n",
        "current_year = now.year\n",
        "\n",
        "df = df[pd.DatetimeIndex(df[\"timestamp\"]).year <= current_year]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ebAO_cH8Kod"
      },
      "source": [
        "## 5.4 Exercise: Remove Outliers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwzRJI1k6kr5"
      },
      "source": [
        "# YOUR CODE GOES HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvtRuawg3vYu"
      },
      "source": [
        "Q1 = df['rating'].quantile(0.25)\n",
        "Q3 = df['rating'].quantile(0.75)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSYn024D3z6N"
      },
      "source": [
        "df[\"rating\"].unique()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqnl8YOo310z"
      },
      "source": [
        "df = df[df[\"rating\"] < 99]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}